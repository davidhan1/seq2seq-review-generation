{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from rouge import Rouge\n",
    "import json, torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge(pred, tar):\n",
    "    rouge = Rouge()  \n",
    "    rouge_score = rouge.get_scores(pred, tar, avg=True)\n",
    "    r1 = rouge_score[\"rouge-1\"]['f']\n",
    "    r2 = rouge_score[\"rouge-2\"]['f']\n",
    "    rl = rouge_score[\"rouge-l\"]['f']\n",
    "    return r1, r2, rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import *\n",
    "from models.attention import Seq2SeqAttn\n",
    "from models.rnn_only import Seq2SeqRNN\n",
    "import json\n",
    "\n",
    "# load data\n",
    "with open('data/seq2seq_dataset.json', 'r', encoding='utf8') as f:\n",
    "    raw = json.load(f)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "enc_char2id_path = 'ckpt/enc_char2id.json'\n",
    "dec_char2id_path = 'ckpt/dec_char2id.json'\n",
    "wordlib_path = 'data/WordLib.json'\n",
    "model_class = Seq2SeqRNN\n",
    "need_scr = True\n",
    "bidirectional = False\n",
    "# RNN\n",
    "model_path = 'ckpt/RNN.pt'\n",
    "rnn_type = 'RNN'\n",
    "rnn = Generator(enc_char2id_path, dec_char2id_path, model_path, wordlib_path, device, need_scr, model_class, bidirectional, rnn_type)\n",
    "# GRU\n",
    "model_path = 'ckpt/GRU.pt'\n",
    "rnn_type = 'GRU'\n",
    "gru = Generator(enc_char2id_path, dec_char2id_path, model_path, wordlib_path, device, need_scr, model_class, bidirectional, rnn_type)\n",
    "# LSTM\n",
    "model_path = 'ckpt/LSTM.pt'\n",
    "rnn_type = 'LSTM'\n",
    "lstm = Generator(enc_char2id_path, dec_char2id_path, model_path, wordlib_path, device, need_scr, model_class, bidirectional, rnn_type)\n",
    "# BiLSTM\n",
    "model_path = 'ckpt/BiLSTM.pt'\n",
    "rnn_type = 'LSTM'\n",
    "bidirectional = True\n",
    "bilstm = Generator(enc_char2id_path, dec_char2id_path, model_path, wordlib_path, device, need_scr, model_class, bidirectional, rnn_type)\n",
    "# attention\n",
    "model_class = Seq2SeqAttn\n",
    "need_scr = False\n",
    "model_path = 'ckpt/attention.pt'\n",
    "rnn_type = None\n",
    "attention = Generator(enc_char2id_path, dec_char2id_path, model_path, wordlib_path, device, need_scr, model_class, bidirectional, rnn_type)\n",
    "# attention_s\n",
    "model_class = Seq2SeqAttn\n",
    "need_scr = True\n",
    "model_path = 'ckpt/attention_s.pt'\n",
    "rnn_type = None\n",
    "attention_s = Generator(enc_char2id_path, dec_char2id_path, model_path, wordlib_path, device, need_scr, model_class, bidirectional, rnn_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(generator):\n",
    "    test_dict = defaultdict(list)\n",
    "\n",
    "    test_dict = sorted(test_dict.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    bleu1 = []\n",
    "    bleu2 = []\n",
    "    bleu3 = []\n",
    "    bleu4 = []\n",
    "    rouge1 = []\n",
    "    rouge2 = []\n",
    "    rougel = []\n",
    "    unigram = []\n",
    "    bigram = []\n",
    "\n",
    "            \n",
    "    for i in tqdm(range(1, 101)):\n",
    "        cur_d = raw[-i]\n",
    "        txt = cur_d['text']\n",
    "        scr = [cur_d['diversity_score'], cur_d['central_score'], cur_d['nov_score'], cur_d['fluent_score']]\n",
    "        cmt = cur_d['cmts'][0]\n",
    "        cmt_in = cmt[:4]\n",
    "        target_text = [[x for x in cmt[len(cmt_in):]]]\n",
    "        prediction = generator.evaluate(txt, scr, cmt_in)\n",
    "        # print(prediction)\n",
    "        prediction = prediction[len(cmt_in):]\n",
    "        unigram += [c for c in prediction]\n",
    "        bigram += [prediction[i:i + 2] for i in range(len(prediction) - 1)]\n",
    "        bleu1.append(sentence_bleu(target_text, [x for x in prediction], (1, 0, 0, 0)))\n",
    "        bleu2.append(sentence_bleu(target_text, [x for x in prediction], (0, 1, 0, 0)))\n",
    "        bleu3.append(sentence_bleu(target_text, [x for x in prediction], (0, 0, 1, 0)))\n",
    "        bleu4.append(sentence_bleu(target_text, [x for x in prediction], (0, 0, 0, 1)))\n",
    "        r1, r2, rl = 0, 0, 0\n",
    "        for l in target_text:\n",
    "            tr1, tr2, trl = rouge([' '.join([x for x in prediction])], [' '.join(l)])\n",
    "            r1 = max(r1, tr1)\n",
    "            r2 = max(r2, tr2)\n",
    "            rl = max(rl, trl)\n",
    "        rouge1.append(r1)\n",
    "        rouge2.append(r2)\n",
    "        rougel.append(rl) \n",
    "\n",
    "\n",
    "    def mean(l):\n",
    "        return sum(l) / len(l)\n",
    "\n",
    "    print('BLEU-1:', mean(bleu1))\n",
    "    print('BLEU-2:', mean(bleu2))\n",
    "    print('BLEU-3:', mean(bleu3))\n",
    "    print('BLEU-4:', mean(bleu4))\n",
    "    print('ROUGE-1:', mean(rouge1))\n",
    "    print('ROUGE-2:', mean(rouge2))\n",
    "    print('ROUGE-L:', mean(rougel))\n",
    "    print('Dist-1:', len(set(unigram)) / len(unigram))\n",
    "    print('Dist-2:', len(set(bigram)) / len(bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 33.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.2580993311625956\n",
      "BLEU-2: 0.08585039610603784\n",
      "BLEU-3: 0.03495045514557055\n",
      "BLEU-4: 0.011183665451404283\n",
      "ROUGE-1: 0.25645832020045223\n",
      "ROUGE-2: 0.103161012546168\n",
      "ROUGE-L: 0.2356874533681517\n",
      "Dist-1: 0.1450171821305842\n",
      "Dist-2: 0.359409594095941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_metrics(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ed10f5784f12228747e42e26f514e267e76a9e7690185e5f867398dba80b904"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
